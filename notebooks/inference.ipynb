{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7eaa91e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from PIL import Image\n",
    "import face_recognition\n",
    "from tqdm import tqdm_notebook\n",
    "import pytube\n",
    "from fastai.vision.all import *\n",
    "from deepface import DeepFace\n",
    "import time\n",
    "import torchaudio, torch\n",
    "import moviepy.editor as mp\n",
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3bd2e270",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "temp = pathlib.PosixPath\n",
    "pathlib.PosixPath = pathlib.WindowsPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "81e2d74c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adnan\\Desktop\\Data Science\\Final Capstone Project\n"
     ]
    }
   ],
   "source": [
    "cd C:\\Users\\Adnan\\Desktop\\Data Science\\Final Capstone Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c0442c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "version = 3\n",
    "model_path = f'models/gaze-recognizer-v{version}.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "58b73f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_learner(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "52ee66f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "backends = [\n",
    "  'opencv', \n",
    "  'ssd', \n",
    "  'dlib', \n",
    "  'mtcnn', \n",
    "  'retinaface', \n",
    "  'mediapipe'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a65d48f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in audio.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is strongly recommended to pass the `sampling_rate` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Hey, just want to tell you you're doing good You're doing your absolute best you're trying your absolute hardest and that's what really matters Don't be so hard on yourself You're doing amazing and if nobody told you lately, I'm proud of you\n",
      "905\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0502eefaee5f4ed4a76830bf12728fed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/905 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Finding actions:   0%|                                                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Action: emotion:   0%|                                                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.58it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'angry': 0.7732846308499575, 'disgust': 1.5110309448118642e-06, 'fear': 1.156102679669857, 'happy': 66.71609878540039, 'sad': 26.12876296043396, 'surprise': 0.00797897155280225, 'neutral': 5.217772722244263}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on_camera\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Finding actions:   0%|                                                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Action: emotion:   0%|                                                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.58it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'angry': 8.151961863040924, 'disgust': 0.002126334948115982, 'fear': 0.41159880347549915, 'happy': 40.70858061313629, 'sad': 50.624603033065796, 'surprise': 7.738518092992308e-06, 'neutral': 0.10111704468727112}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on_camera\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Finding actions:   0%|                                                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 15.98it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'angry': 0.03949433157686144, 'disgust': 1.4949245183762394e-10, 'fear': 0.0017348404071526602, 'happy': 99.8606026172638, 'sad': 0.014265705249272287, 'surprise': 0.004526855263975449, 'neutral': 0.07938353810459375}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on_camera\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Finding actions:   0%|                                                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 16.25it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'angry': 0.0014545236808771733, 'disgust': 6.31178594633075e-12, 'fear': 0.01961608068086207, 'happy': 99.95170831680298, 'sad': 1.3689509614778217e-05, 'surprise': 0.011821027146652341, 'neutral': 0.015392844215966761}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on_camera\n",
      "focus perfectage = 100.0\n",
      "total anger percentage = 2.241548837287155\n",
      "total disgust percentage = 0.0005319615337162579\n",
      "total fear percentage = 0.3972631010583427\n",
      "total happy percentage = 76.80924758315086\n",
      "total sad percentage = 19.19191134706466\n",
      "total surprise percentage = 0.006083648120380758\n",
      "total neutral percentage = 1.3534165373130236\n",
      "7.6690661907196045\n"
     ]
    }
   ],
   "source": [
    "angry = 0\n",
    "disgust = 0\n",
    "fear = 0\n",
    "happy = 0\n",
    "sad = 0\n",
    "surprise = 0\n",
    "neutral = 0\n",
    "emotion_count = 0\n",
    "# Open the video file\n",
    "video_source = 'source_videos/A message from longbeachgriffy.mp4'\n",
    "video_capture = cv2.VideoCapture(video_source)\n",
    "transcription = getTranscription(video_source)\n",
    "print(transcription)\n",
    "\n",
    "# Get the total number of frames in the video\n",
    "total_frames = int(video_capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "print(total_frames)\n",
    "start = time.time()\n",
    "# Loop through the frames of the video\n",
    "# while True:\n",
    "on_camera = 0\n",
    "off_camera = 0\n",
    "total = 0\n",
    "for _ in tqdm_notebook(range(total_frames)):\n",
    "    # Read a single frame from the video\n",
    "    for i in range(24*5):\n",
    "        ret, frame = video_capture.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "    # If there are no more frames, break out of the loop\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Convert the frame to RGB color (face_recognition uses RGB)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "\n",
    "    # Find all the faces in the frame using a pre-trained convolutional neural network.\n",
    "    face_locations = face_recognition.face_locations(gray)\n",
    "    #face_locations = face_recognition.face_locations(gray, number_of_times_to_upsample=0, model=\"cnn\")\n",
    "\n",
    "    if len(face_locations) > 0:\n",
    "        # Show the original frame with face rectangles drawn around the faces\n",
    "        for top, right, bottom, left in face_locations:\n",
    "            cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "            face_image = gray[top:bottom, left:right]\n",
    "            color_image = frame[top:bottom, left:right]\n",
    "            #plt.imshow(face_image[:,::-1])\n",
    "\n",
    "            # Resize the face image to the desired size\n",
    "            resized_face_image = cv2.resize(face_image, (128,128))\n",
    "            \n",
    "            try:\n",
    "                emotion = DeepFace.analyze(color_image,actions=['emotion'],detector_backend = backends[2],enforce_detection = False)# 2,3, 4 works\n",
    "                emotion_count += 1\n",
    "                print(emotion[0]['emotion'])\n",
    "                angry += emotion[0]['emotion']['angry']\n",
    "                disgust += emotion[0]['emotion']['disgust']\n",
    "                fear += emotion[0]['emotion']['fear']\n",
    "                happy += emotion[0]['emotion']['happy']\n",
    "                sad += emotion[0]['emotion']['sad']\n",
    "                surprise += emotion[0]['emotion']['surprise']\n",
    "                neutral += emotion[0]['emotion']['neutral']\n",
    "            except Exception as e:\n",
    "                pass\n",
    "            \n",
    "\n",
    "            #emotions = emotions+emotion.emotion\n",
    "            # 4 took 110 3 took 58 2 took 57\n",
    "\n",
    "            # Predict the class of the resized face image using the model\n",
    "            result = model.predict(resized_face_image)\n",
    "            print(result[0])\n",
    "            if(result[0] == 'on_camera'): on_camera = on_camera + 1\n",
    "            elif(result[0] == 'off_camera'): off_camera = off_camera + 1\n",
    "            total = total + 1\n",
    "        \n",
    "    cv2.imshow('Video', frame)\n",
    "\n",
    "    # If the user presses the 'q' key, exit the loop\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "# print(total,on_camera,off_camera)\n",
    "print(f'focus perfectage = {on_camera/total*100}')\n",
    "# Release the video capture object and close all windows\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()\n",
    "angry = angry / emotion_count\n",
    "disgust = disgust / emotion_count\n",
    "fear = fear / emotion_count\n",
    "happy = happy / emotion_count\n",
    "sad = sad / emotion_count\n",
    "surprise = surprise / emotion_count\n",
    "neutral = neutral / emotion_count\n",
    "print(f'total anger percentage = {angry}')\n",
    "print(f'total disgust percentage = {disgust}')\n",
    "print(f'total fear percentage = {fear}')\n",
    "print(f'total happy percentage = {happy}')\n",
    "print(f'total sad percentage = {sad}')\n",
    "print(f'total surprise percentage = {surprise}')\n",
    "print(f'total neutral percentage = {neutral}')\n",
    "end = time.time()\n",
    "print(end-start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "05f7e8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTranscription(path):\n",
    "    # Insert Local Video File Path\n",
    "    clip = mp.VideoFileClip(path)\n",
    "\n",
    "    # Insert Local Audio File Path\n",
    "    clip.audio.write_audiofile(r\"audio.wav\")\n",
    "    \n",
    "    waveform, sample_rate = torchaudio.load(\"audio.wav\")\n",
    "    resampler = torchaudio.transforms.Resample(sample_rate, 16000)\n",
    "    waveform = resampler(waveform)[0]\n",
    "    \n",
    "    processor = WhisperProcessor.from_pretrained(\"openai/whisper-tiny\")\n",
    "    model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-tiny\")\n",
    "    model.config.forced_decoder_ids = None\n",
    "    \n",
    "    input_features = processor(waveform.squeeze(dim=0), return_tensors=\"pt\").input_features \n",
    "    predicted_ids = model.generate(input_features)\n",
    "\n",
    "    transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)\n",
    "    \n",
    "    return transcription[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0586e06a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
